defaults:
  data_dir:
    VoxCeleb1: 'data/raw/VoxCeleb1'
    VoxCeleb2: 'data/raw/VoxCeleb2'
  map_file:
    VoxCeleb1: 'data/interim/VoxCeleb1/{}_{}_map.pkl'
    VoxCeleb2: 'data/interim/VoxCeleb2/{}_{}_map.pkl'
  meta_file:
    VoxCeleb1: 'data/raw/VoxCeleb1/vox1_meta.csv'
    VoxCeleb2: 'data/raw/VoxCeleb1/vox2_meta.csv'
  save_path: 'models/checkpoints/{}'
  save_format: '%Y-%b-%d-%H:%M:%S'
  num_classes: 1251
  num_workers: 4
hparams:
  win_size: 25
  hop_len: 10
  window_type: 'hann'
  num_workers: 1
  sf: 16000
  num_classes: 1251
  batch_size: 64
  epochs: 100
  adam_eps: 0.001
  val_step: 100000
  val_start: 99999
  preprocess: True
  duration: 3.0
  overlap: 0.5
  cnn:
    sf: 16000
    input_dim: 16000
    num_filters: [80, 60, 60]
    filter_lens: [251, 5, 5]
    max_pool_lens: [3, 3, 3]
    input_normalization: 'layer'
    normalization: ['layer', 'layer', 'layer']
    act_funs: ['relu', 'relu', 'relu']
    drop_probs: [0.0, 0.0, 0.0]
  dnn:
    layer_dims: [2048, 2048]
    input_normalization: 'layer'
    normalization: ['batch', 'batch']
    act_funs: ['leaky_relu', 'linear']
    drop_probs: [0.0, 0.0, 0.0]
  class:
    layer_dims: [2048, 1251]
    input_normalization: 'layer'
    normalization: ['batch', None]
    act_funs: ['relu', 'softmax']
    drop_probs: [0.0, 0.0, 0.0]
  optimizer:
    rmsprop:
      params:
        learning_rate: 0.001
        alpha: 0.95
        weight_decay: 0.0
    sgd:
      params:
        init_lr: 1.0e-2
        fin_lr: 1.0e-8
        decay_schedule: 'logarithmic'
        last_epoch: 30
        weight_decay: 5.0e-4
        # decay_filters: ['bias', 'bn', 'downsample.1']
    adam:
      params:
        learning_rate: 0.001
        weight_decay: 5.0e-4
